{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fda9d9-5fb6-4341-a417-b7222aa954d9",
   "metadata": {},
   "source": [
    "# Video Recommendation Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd3304-dd5e-4896-ad81-cd1e93226561",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 2\n",
    "# Enhanced Documentation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import JSON\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814b19a-f850-44ed-946a-160d81dc3f7d",
   "metadata": {},
   "source": [
    "## 1.) Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2342e0-2028-4f4b-8f82-c2d037201537",
   "metadata": {},
   "source": [
    "### 1.1) Extracting data from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 5\n",
    "# Enhanced Documentation\n",
    "base_url = \"https://api.socialverseapp.com\"\n",
    "headers = {\n",
    "    \"Flic-Token\": \"flic_1e01009f9c1a54706f385bcc1993a08fd9647ba8f499572d280654d1c03c47bf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe521f-46bd-4ba4-b575-6be1b1cd1ad0",
   "metadata": {},
   "source": [
    "#### All Viewed Posts of Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 7\n",
    "# Enhanced Documentation\n",
    "viewed_url = f\"{base_url}/posts/view?page=1&page_size=1000&resonance_algorithm=resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "response = requests.get(viewed_url ,headers=headers)\n",
    "json_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 8\n",
    "# Enhanced Documentation\n",
    "# Extracting data from JSON\n",
    "data = []\n",
    "for entry in json_data.get(\"posts\", []):\n",
    "    data.append({\n",
    "        \"id\": entry[\"id\"],\n",
    "        \"category_id\": entry[\"category\"][\"id\"],\n",
    "        \"category\": entry[\"category\"][\"name\"],\n",
    "        \"User\": entry[\"first_name\"]+entry[\"last_name\"],\n",
    "        \"username\": entry[\"username\"],\n",
    "        # \"post_slug\": entry[\"slug\"],\n",
    "        \"title\": entry[\"title\"],\n",
    "        \"identifier\": entry[\"identifier\"],\n",
    "        \"comment_count\": entry[\"comment_count\"],\n",
    "        \"upvote_count\": entry[\"upvote_count\"],\n",
    "        \"view_count\": entry[\"view_count\"],\n",
    "        \"exit_count\": entry[\"exit_count\"],\n",
    "        \"rating_count\": entry[\"rating_count\"],\n",
    "        \"average_rating\": entry[\"average_rating\"],\n",
    "        \"share_count\": entry[\"share_count\"],\n",
    "        \"upvoted\": entry[\"upvoted\"],\n",
    "        \"bookmarked\": entry[\"bookmarked\"],\n",
    "        \"following\": entry[\"following\"]\n",
    "    })\n",
    "    \n",
    "viewed_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 9\n",
    "# Enhanced Documentation\n",
    "viewed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 10\n",
    "# Enhanced Documentation\n",
    "viewed_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa399c-b294-4e84-b172-4383c6be613c",
   "metadata": {},
   "source": [
    "#### Extract All Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90756fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 12\n",
    "# Enhanced Documentation\n",
    "post_url = f\"{base_url}/posts/summary/get?page=1&page_size=1000\"\n",
    "response = requests.get(post_url, headers=headers)\n",
    "json_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9991d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 13\n",
    "# Enhanced Documentation\n",
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 14\n",
    "# Enhanced Documentation\n",
    "json_data[\"posts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 15\n",
    "# Enhanced Documentation\n",
    "posts = json_data[\"posts\"]\n",
    "data = []\n",
    "\n",
    "for post in posts:\n",
    "    data.append({\n",
    "        'id': post['id'],\n",
    "        'title': post['title'],\n",
    "        'category': post['category']['name'],\n",
    "        'username': post['username'],\n",
    "        'view_count': post['view_count'],\n",
    "        'upvote_count': post['upvote_count'],\n",
    "        'comment_count': post['comment_count'],\n",
    "        'rating-count': post['rating_count'],\n",
    "        'average_rating': post['average_rating'],\n",
    "        'post_summary': post['post_summary']\n",
    "    })\n",
    "\n",
    "post_df = pd.DataFrame(data)\n",
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb051784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 16\n",
    "# Enhanced Documentation\n",
    "post_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994de474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 17\n",
    "# Enhanced Documentation\n",
    "def mergeList(L):\n",
    "    if isinstance(L, list):\n",
    "        return \", \".join(str(item) for item in L)  \n",
    "    return str(L) if L is not None else \"\"\n",
    "\n",
    "def convert(text):\n",
    "    if not isinstance(text, dict):  # Check if text is a dictionary\n",
    "        print(\"Error: Expected dictionary, got:\", type(text))\n",
    "        return []\n",
    "    L = []\n",
    "    descr = text[\"description\"]\n",
    "    if isinstance(descr, list): descr = mergeList(descr)\n",
    "    genre = text.get(\"genre\", \"\")\n",
    "    if not isinstance(genre, str):\n",
    "        genre = \" \"\n",
    "\n",
    "    # Handle actions based on data type\n",
    "    if isinstance(text[\"actions\"], list):\n",
    "        # action = \" \".join(text[\"actions\"])\n",
    "        action = \" \".join([str(item) if isinstance(item, str) else mergeList(item.values()) for item in text[\"actions\"]])\n",
    "    elif isinstance(text[\"actions\"], dict):\n",
    "        first_key = list(text[\"actions\"].keys())[0]\n",
    "        action = mergeList(text[\"actions\"][first_key])\n",
    "        if isinstance(action, dict):\n",
    "            action = \"\"\n",
    "    else:\n",
    "        action = \"\"\n",
    "    \n",
    "    # Handle emotions based on data type\n",
    "    if isinstance(text[\"emotions\"], list):\n",
    "        # emotion = \" \".join(text[\"emotions\"])\n",
    "        emotion = \" \".join([str(item) if isinstance(item, str) else mergeList(item.values()) for item in text[\"targeted_audiance\"]])\n",
    "    elif isinstance(text[\"emotions\"], dict):\n",
    "        first_key = list(text[\"emotions\"].keys())[0]\n",
    "        emotion = mergeList(text[\"emotions\"][first_key]) \n",
    "    else:\n",
    "        emotion = \"\"\n",
    "\n",
    "    # Handle audience based on data type\n",
    "    if isinstance(text[\"targeted_audiance\"], list):\n",
    "        # audience = \" \".join(text[\"targeted_audiance\"])\n",
    "        audience = \" \".join([str(item) if isinstance(item, str) else mergeList(item.values()) for item in text[\"targeted_audiance\"]])\n",
    "    elif isinstance(text[\"targeted_audiance\"], dict):\n",
    "        first_key = list(text[\"targeted_audiance\"].keys())[0]\n",
    "        audience = mergeList(text[\"targeted_audiance\"][first_key])\n",
    "    else:\n",
    "        audience = \"\"\n",
    "        \n",
    "    # Handle psychological view based on its data type\n",
    "    if isinstance(text[\"psycological_view_of_video\"], list):\n",
    "        # psych = \" \".join(text[\"psycological_view_of_video\"])\n",
    "        psych = \" \".join([str(item) if isinstance(item, str) else mergeList(item.values()) for item in text[\"psycological_view_of_video\"]])\n",
    "    elif isinstance(text[\"psycological_view_of_video\"], dict):\n",
    "        first_key = list(text[\"psycological_view_of_video\"].keys())[0]\n",
    "        psych = mergeList(text[\"psycological_view_of_video\"][first_key])\n",
    "    else:\n",
    "        psych = \"\"\n",
    "\n",
    "    L.append(action+descr+emotion+genre+audience+psych)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 18\n",
    "# Enhanced Documentation\n",
    "post_df[\"post_summary\"] = post_df[\"post_summary\"].apply(convert)\n",
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98502a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 19\n",
    "# Enhanced Documentation\n",
    "post_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c14580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 20\n",
    "# Enhanced Documentation\n",
    "def collapse(L):\n",
    "    return L[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 21\n",
    "# Enhanced Documentation\n",
    "post_df['post_summary'] = post_df['post_summary'].apply(lambda x: x[0] if isinstance(x, list) and x else x)\n",
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202e4d8-a950-4129-9828-1e4535a8dd8a",
   "metadata": {},
   "source": [
    "#### Extract All Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 23\n",
    "# Enhanced Documentation\n",
    "user_url = f\"{base_url}/users/get_all?page=1&page_size=1000\"\n",
    "response = requests.get(user_url, headers=headers)\n",
    "json_data = response.json()\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743fcf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 24\n",
    "# Enhanced Documentation\n",
    "def extract_user_data(data):\n",
    "    # Check if 'users' key exists in the input data\n",
    "    if 'users' not in data:\n",
    "        return []\n",
    "\n",
    "    # Extract only the needed fields for each user\n",
    "    extracted_data = [\n",
    "        {\n",
    "            'user_id': user.get('id', ''),\n",
    "            'user': user.get('first_name', '')+user.get('last_name', ''),\n",
    "            'username': user.get('username', ''),\n",
    "            'bio': user.get('bio', ''),\n",
    "            'post_count': user.get('post_count', 0),\n",
    "            'follower_count': user.get('follower_count', 0),\n",
    "            'following_count': user.get('following_count', 0)\n",
    "        }\n",
    "        for user in data['users']\n",
    "    ]\n",
    "    \n",
    "    return extracted_data\n",
    "clean_data = extract_user_data(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 25\n",
    "# Enhanced Documentation\n",
    "user_df = pd.DataFrame(clean_data)\n",
    "user_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406fc15-bb35-47bb-b3a7-cab351ab5f5f",
   "metadata": {},
   "source": [
    "### 1.2) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 27\n",
    "# Enhanced Documentation\n",
    "\"\"\"\n",
    "we have \n",
    "post_df - all post\n",
    "viewed_df - all vwed post\n",
    "user_df - all users\n",
    "\n",
    "\"\"\"\n",
    "# looking at users_df\n",
    "user_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32af60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 28\n",
    "# Enhanced Documentation\n",
    "# chceking null values in user_df\n",
    "user_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90819d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Documentation added to cell 29\n",
    "# Enhanced Documentation\n",
    "# Mathematical Analysis of user_df\n",
    "user_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e60202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 30\n",
    "# Enhanced Documentation\n",
    "\"\"\"\n",
    "form this we can infer that 75% of people have not posted more than 40 videos\n",
    "\"\"\"\n",
    "user_df[user_df[\"post_count\"] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db93e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 31\n",
    "# Enhanced Documentation\n",
    "user_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d530d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 32\n",
    "# Enhanced Documentation\n",
    "# Looking at post_df\n",
    "post_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f12ee-d2b2-4088-afc7-c3f6c4066358",
   "metadata": {},
   "source": [
    "From this we can infer that there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 34\n",
    "# Enhanced Documentation\n",
    "post_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079b006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Documentation added to cell 35\n",
    "# Enhanced Documentation\n",
    "post_df[post_df['rating-count'] >= 5].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 36\n",
    "# Enhanced Documentation\n",
    "# Looking at viewed_df\n",
    "viewed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1c846-08a9-469e-872c-39efc50a6386",
   "metadata": {},
   "source": [
    "From this we can infer that there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 38\n",
    "# Enhanced Documentation\n",
    "viewed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c3c83-97f7-403e-a15a-3e4a2a08c6ef",
   "metadata": {},
   "source": [
    "## 2.) Algorithm Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbf032a-2d73-4b51-8fde-cbb138900d14",
   "metadata": {},
   "source": [
    "### 2.1) Cold Start Problem Handling - Popularity Based Recommendations\n",
    "Using post_df we can use the comment_count, view_count, upvote_count and average_rating as metrics to derive a new feature \"trending_score\" and then find the top trending post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85adcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 41\n",
    "# Enhanced Documentation\n",
    "def calculate_trending_score(recommend_df, view_weight=0.5, upvote_weight=0.1, comment_weight=0.1, avg_rating_weight=0.3):\n",
    "    # Ensure no NaN values during calculation\n",
    "    recommend_df = recommend_df.fillna({\n",
    "        'view_count': 0,\n",
    "        'upvote_count': 0,\n",
    "        'comment_count': 0,\n",
    "        'average_rating': 0\n",
    "    })\n",
    "    \n",
    "    recommend_df['trending_score'] = (\n",
    "        (recommend_df['view_count'] * view_weight) + \n",
    "        (recommend_df['upvote_count'] * upvote_weight) + \n",
    "        (recommend_df['comment_count'] * comment_weight) +\n",
    "        (recommend_df['average_rating'] * avg_rating_weight)\n",
    "    )\n",
    "    return recommend_df\n",
    "\n",
    "# Apply the trending score to post_df\n",
    "post_df = calculate_trending_score(post_df)\n",
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 42\n",
    "# Enhanced Documentation\n",
    "# Ranking the videos by trending score\n",
    "def get_trending_recommendations(recommend_df, top_n=10):\n",
    "    if recommend_df.empty:\n",
    "        print(\"No data available to recommend trending videos.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    trending_videos = recommend_df.sort_values(by='trending_score', ascending=False)\n",
    "    trending_videos = trending_videos.drop_duplicates(subset='id')  # Remove duplicates by ID\n",
    "    \n",
    "    # Select the top N videos\n",
    "    return trending_videos.head(top_n)[['id', 'title', 'category', 'trending_score']]\n",
    "\n",
    "# Example usage\n",
    "top_recommendations = get_trending_recommendations(post_df)\n",
    "top_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a9dc3-9e3f-4e7f-9f28-f3a40e178a43",
   "metadata": {},
   "source": [
    "### 2.2) Content Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebba7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 44\n",
    "# Enhanced Documentation\n",
    "content_df = post_df[['id', 'title']]\n",
    "content_df['tags'] = post_df['post_summary'].astype(str)\n",
    "content_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 45\n",
    "# Enhanced Documentation\n",
    "# Applying stemming\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4604f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 46\n",
    "# Enhanced Documentation\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(stemmer.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 47\n",
    "# Enhanced Documentation\n",
    "content_df['tags'] = content_df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1038260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 48\n",
    "# Enhanced Documentation\n",
    "# creating a vector of tags\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 49\n",
    "# Enhanced Documentation\n",
    "vectors = vectorizer.fit_transform(content_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270810bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 50\n",
    "# Enhanced Documentation\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 51\n",
    "# Enhanced Documentation\n",
    "# Finding Cosine similarity of vectors\n",
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 52\n",
    "# Enhanced Documentation\n",
    "# Content-based recommendation function\n",
    "def content_based_recommend(video):\n",
    "    if video not in content_df['title'].values:\n",
    "        return f\"Video '{video}' not found in the dataset.\"\n",
    "    \n",
    "    video_index = content_df[content_df['title'] == video].index[0]\n",
    "    distances = similarity[video_index]\n",
    "    video_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
    "    \n",
    "    recommendations = []\n",
    "    for i in video_list:\n",
    "        recommendations.append(content_df.iloc[i[0]].title)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 53\n",
    "# Enhanced Documentation\n",
    "print(content_based_recommend('Why fit in..?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bfd66-c7df-4ab7-a06c-e8585e8e4dab",
   "metadata": {},
   "source": [
    "### 2.3) Collaborative Recommendations Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 55\n",
    "# Enhanced Documentation\n",
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ddb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 56\n",
    "# Enhanced Documentation\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae74422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 57\n",
    "# Enhanced Documentation\n",
    "# Step 1: Prepare Data for Collaborative Filtering\n",
    "# Use 'user_id', 'post_id' and a feedback score as interaction (view count or upvote count)\n",
    "interaction_data = viewed_df[['username', 'id']]\n",
    "interaction_data.columns = ['username', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 58\n",
    "# Enhanced Documentation\n",
    "# Aggregate multiple metrics into a single score\n",
    "interaction_data['interaction_score'] = (\n",
    "    viewed_df['view_count'] * 0.4 +  # Weight for view count\n",
    "    viewed_df['upvote_count'] * 0.3 +  # Weight for upvotes\n",
    "    viewed_df['average_rating'] * 0.2 +  # Weight for average rating\n",
    "    viewed_df['comment_count'] * 0.1  # Weight for comments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 59\n",
    "# Enhanced Documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a446092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 60\n",
    "# Enhanced Documentation\n",
    "# Drop duplicates for the same id and username\n",
    "interaction_data = interaction_data.drop_duplicates(subset=['id', 'username'], keep='first')\n",
    "\n",
    "# Clip the interaction_score between 1 and 10\n",
    "interaction_data['interaction_score'] = interaction_data['interaction_score'].clip(1, 10)\n",
    "len(interaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6338ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 61\n",
    "# Enhanced Documentation\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(\n",
    "    interaction_data[['username', 'id', 'interaction_score']],\n",
    "    reader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 62\n",
    "# Enhanced Documentation\n",
    "# Step 3: Train-Test Split\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76567d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 63\n",
    "# Enhanced Documentation\n",
    "# Step 4: Use SVD (Singular Value Decomposition) for Matrix Factorization\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff63b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 64\n",
    "# Enhanced Documentation\n",
    "# Step 5: Evaluate the Model\n",
    "predictions = algo.test(testset)\n",
    "print(f'RMSE: {accuracy.rmse(predictions)}')  # Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 65\n",
    "# Enhanced Documentation\n",
    "# Step 6: Function to Recommend Videos for a Specific User\n",
    "def collaborative_recommendations(username, post_df, algo, top_n=10):\n",
    "    # Get a list of post IDs the user has not interacted with\n",
    "    viewed_posts = interaction_data[interaction_data['username'] == username]['id'].tolist()\n",
    "    all_posts = post_df['id'].tolist()\n",
    "    posts_to_recommend = [post for post in all_posts if post not in viewed_posts]\n",
    "    \n",
    "    # Predict ratings for unseen posts\n",
    "    predictions = [algo.predict(username, id) for id in posts_to_recommend]\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Get top N recommendations\n",
    "    top_predictions = predictions[:top_n]\n",
    "    top_ids = [pred.iid for pred in top_predictions]\n",
    "    \n",
    "    # Return recommended posts\n",
    "    recommended_posts = post_df[post_df['id'].isin(top_ids)][['id', 'title', 'category']]\n",
    "    return recommended_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be970d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 66\n",
    "# Enhanced Documentation\n",
    "user_df.iloc[159]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 67\n",
    "# Enhanced Documentation\n",
    "# Step 7: Test Recommendations for a User\n",
    "username = user_df['username'].iloc[4]  # Example: using the first user in user_df\n",
    "recommended_videos = collaborative_recommendations(username, post_df, algo)\n",
    "print(recommended_videos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 68\n",
    "# Enhanced Documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3c6f0-542f-4ddf-a276-e72af2c41833",
   "metadata": {},
   "source": [
    "### 2.4) Hybrid Recommendation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f329d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 70\n",
    "# Enhanced Documentation\n",
    "def hybrid_recommender(username, video_title, post_df, algo, content_weight=0.5, collab_weight=0.5, top_n=10):\n",
    "    \"\"\"\n",
    "    Combine content-based and collaborative filtering recommendations.\n",
    "\n",
    "    Parameters:\n",
    "    - username: str, the username for collaborative recommendations.\n",
    "    - video_title: str, the video title for content-based recommendations.\n",
    "    - post_df: DataFrame, containing post data with 'id', 'title', 'category'.\n",
    "    - algo: Collaborative filtering algorithm object.\n",
    "    - content_weight: float, weight for content-based recommendations.\n",
    "    - collab_weight: float, weight for collaborative recommendations.\n",
    "    - top_n: int, number of recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame of top hybrid recommendations.\n",
    "    \"\"\"\n",
    "    # Get content-based recommendations\n",
    "    content_recommendations = content_based_recommend(video_title)\n",
    "\n",
    "    # Map content-based recommendations to their post IDs\n",
    "    content_post_ids = post_df[post_df['title'].isin(content_recommendations)][['id', 'title']]\n",
    "\n",
    "    # Get collaborative recommendations\n",
    "    collab_recommendations = collaborative_recommendations(username, post_df, algo, top_n=top_n)\n",
    "\n",
    "    # Merge recommendations\n",
    "    # Assign normalized scores to content-based and collaborative recommendations\n",
    "    content_post_ids['score'] = content_weight\n",
    "    collab_recommendations['score'] = collab_weight\n",
    "\n",
    "    # Combine both recommendation lists\n",
    "    combined_recommendations = pd.concat([content_post_ids, collab_recommendations], ignore_index=True)\n",
    "\n",
    "    # Group by video ID, sum scores, and sort by the highest score\n",
    "    combined_recommendations = (\n",
    "        combined_recommendations.groupby(['id', 'title', 'category'], as_index=False)['score']\n",
    "        .sum()\n",
    "        .sort_values(by='score', ascending=False)\n",
    "    )\n",
    "\n",
    "    # Return top N recommendations\n",
    "    return combined_recommendations.head(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877631a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 71\n",
    "# Enhanced Documentation\n",
    "print(hybrid_recommender('kinha', 'do it now', post_df, algo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325622d-1ff4-4e12-be5b-166ec633e0f6",
   "metadata": {},
   "source": [
    "## 3.) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc5e10-2580-4de6-8846-256bd4e83b21",
   "metadata": {},
   "source": [
    "### 3.1) CTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19be0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 74\n",
    "# Enhanced Documentation\n",
    "merged_df = viewed_df.merge(post_df, on=['id', 'username', 'category', 'title'], suffixes=('_viewed', '_post'))\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 75\n",
    "# Enhanced Documentation\n",
    "def calculate_ctr(user_df, viewed_df, post_df):\n",
    "    # Merge viewed_df with post_df to include post information\n",
    "    merged_df = viewed_df.merge(post_df, on=['id', 'username', 'category', 'title'], suffixes=('_viewed', '_post'))\n",
    "\n",
    "    # Replace zero values to avoid division errors\n",
    "    merged_df['exit_count'] = np.maximum(merged_df['exit_count'], 1)\n",
    "    merged_df['view_count_post'] = np.maximum(merged_df['view_count_post'], 1)\n",
    "\n",
    "    # Calculate CTR for each post\n",
    "    merged_df['CTR'] = (\n",
    "        (merged_df['share_count'] + merged_df['comment_count_post'] + merged_df['upvote_count_post']) /\n",
    "        (merged_df['view_count_post'] + merged_df['exit_count'])\n",
    "    ) * 100\n",
    "\n",
    "    # Aggregate CTR by post and user\n",
    "    post_ctr = merged_df.groupby('title')['CTR'].mean().reset_index()\n",
    "    user_ctr = merged_df.groupby('username')['CTR'].mean().reset_index()\n",
    "\n",
    "    # Return aggregated results\n",
    "    return post_ctr, user_ctr, merged_df[['id', 'username', 'share_count', 'upvote_count_post', \n",
    "                                          'comment_count_post', 'view_count_post', 'exit_count', 'CTR']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b82eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 76\n",
    "# Enhanced Documentation\n",
    "post_ctr, user_ctr, detailed_ctr = calculate_ctr(user_df, viewed_df, post_df)\n",
    "print(\"CTR by Post:\\n\", post_ctr)\n",
    "print(\"\\nCTR by User:\\n\", user_ctr)\n",
    "print(\"\\nDetailed CTR:\\n\", detailed_ctr.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 77\n",
    "# Enhanced Documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a8c40-6960-4117-8528-6a43b8f74afb",
   "metadata": {},
   "source": [
    "### 3.2) MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 79\n",
    "# Enhanced Documentation\n",
    "def map_util(user_df, post_df, algo, video_title, top_n=10):\n",
    "    recommendations = {}\n",
    "    for user in user_df['username']:\n",
    "        # Get recommendations using hybrid recommender\n",
    "        # recs = hybrid_recommender(user, video_title, post_df, algo, top_n=top_n)\n",
    "        recs = aborative_recommendations(user, post_df, algo)\n",
    "        if not recs.empty:\n",
    "            recommendations[user] = recs['id'].tolist()\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 80\n",
    "# Enhanced Documentation\n",
    "viewed_df.iloc[51]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 81\n",
    "# Enhanced Documentation\n",
    "recommendation = map_util(user_df, post_df, algo, 'Trading memecoins #memecoin #solana #bitcoin #funny #usa #fyp #animation #animationmeme #memecoins #2d #foryou #foryoupage #repost #viraltiktok', top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d261df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 82\n",
    "# Enhanced Documentation\n",
    "recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 83\n",
    "# Enhanced Documentation\n",
    "viewed_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e476b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 84\n",
    "# Enhanced Documentation\n",
    "def calculate_map(viewed_df, post_df, recommendations):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision (MAP) for the recommendations.\n",
    "    \n",
    "    Args:\n",
    "        viewed_df: DataFrame containing the viewed posts for users.\n",
    "        post_df: DataFrame containing post information.\n",
    "        recommendations: Dictionary of {user: [recommended_post_ids]}.\n",
    "        \n",
    "    Returns:\n",
    "        MAP score as a float.\n",
    "    \"\"\"\n",
    "    map_scores = []\n",
    "\n",
    "    for user, recommended_posts in recommendations.items():\n",
    "        # Get the posts that the user has actually viewed\n",
    "        viewed_posts = set(viewed_df[viewed_df['username'] == user]['id'].tolist())\n",
    "        if not viewed_posts:\n",
    "            continue\n",
    "        print(user)\n",
    "        print(\"recom= \", recommended_posts)\n",
    "        # Calculate Average Precision (AP)\n",
    "        relevant, total_precision = 0, 0\n",
    "        for rank, post_id in enumerate(recommended_posts, start=1):\n",
    "            if post_id in viewed_posts:\n",
    "                print(\"oo\")\n",
    "                relevant += 1\n",
    "                total_precision += relevant / rank\n",
    "\n",
    "        # Normalize AP by the number of relevant items (viewed_posts)\n",
    "        avg_precision = total_precision / len(viewed_posts) if viewed_posts else 0\n",
    "        map_scores.append(avg_precision)\n",
    "\n",
    "    # Compute and return Mean Average Precision (MAP)\n",
    "    return sum(map_scores) / len(map_scores) if map_scores else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92933717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 85\n",
    "# Enhanced Documentation\n",
    "# Calculate MAP for the given data and recommendations\n",
    "map_score = calculate_map(viewed_df, post_df, recommendation)\n",
    "\n",
    "print(f\"Mean Average Precision (MAP): {map_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 86\n",
    "# Enhanced Documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 87\n",
    "# Enhanced Documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1683c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 88\n",
    "# Enhanced Documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 89\n",
    "# Enhanced Documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157973d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation added to cell 90\n",
    "# Enhanced Documentation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
